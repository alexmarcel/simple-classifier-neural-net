{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGEFuyIvSfWVBWTqX+06Ga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexmarcel/neural-networks/blob/main/simple_classifier_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torchvision for GPU\n",
        "!pip install torch torchvision pandas matplotlib"
      ],
      "metadata": {
        "id": "8w9sj2UM_Dcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHPLr5PN4rYB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chose device, GPU if exist, if not use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Check device selected\n",
        "print(f'Using device: {device}\\n')\n",
        "\n",
        "# Check GPU device details\n",
        "torch.cuda.is_available()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "_Ra28ZGq_KnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Model Class that inherits nn.Module\n",
        "\n",
        "class Model(nn.Module):\n",
        "  # input layer (number of features of the dataset) -->\n",
        "  # hidden layer 1 (number of neurons) -->\n",
        "  # hidden layer 2 (number of neurons) -->\n",
        "  # hidden layer ... (number of ...) -->\n",
        "  # output (labels)\n",
        "\n",
        "  def __init__(self, in_features=4, h1=128, h2=64, h3=32, h4=16, out_features=3):\n",
        "    super().__init__() # Instantiate nn module\n",
        "    self.hl1 = nn.Linear(in_features, h1)\n",
        "    self.hl2 = nn.Linear(h1, h2)\n",
        "    self.hl3 = nn.Linear(h2, h3)\n",
        "    self.hl4 = nn.Linear(h3, h4)\n",
        "    self.out = nn.Linear(h4, out_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.hl1(x))\n",
        "    x = F.relu(self.hl2(x))\n",
        "    x = F.relu(self.hl3(x))\n",
        "    x = F.relu(self.hl4(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "GoM-KnCq6PXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual seed for randomization\n",
        "torch.manual_seed(10)\n",
        "\n",
        "# Create an instance of model\n",
        "model = Model().to(device) # Move model to selected device (GPU or CPU)"
      ],
      "metadata": {
        "id": "fV0HS13JEdie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "F53xwtywGII4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "my_dataframe = pd.read_csv('iris.csv')\n",
        "\n",
        "# Change last column strings to number\n",
        "my_dataframe['species'] = my_dataframe['species'].replace('Iris-setosa', 0.0)\n",
        "my_dataframe['species'] = my_dataframe['species'].replace('Iris-versicolor', 1.0)\n",
        "my_dataframe['species'] = my_dataframe['species'].replace('Iris-virginica', 2.0)\n",
        "\n",
        "# Check data table\n",
        "my_dataframe"
      ],
      "metadata": {
        "id": "VA6PngN4GSWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset shape (records, features)\n",
        "my_dataframe.shape"
      ],
      "metadata": {
        "id": "1b1xEC9GplIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values in dataset\n",
        "my_dataframe.isnull().values.any()"
      ],
      "metadata": {
        "id": "je5afPTwqgVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset correlation\n",
        "my_dataframe.corr()"
      ],
      "metadata": {
        "id": "BEqxELm0q6g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set X features, y labels\n",
        "X = my_dataframe.drop('species', axis=1)  # Select features, drop label column into X\n",
        "y = my_dataframe['species']               # Select only label column into y\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "# Convert X features to float tensors\n",
        "X_train = torch.FloatTensor(X_train).to(device)  # Move train features data to selected device (GPU or CPU)\n",
        "X_test = torch.FloatTensor(X_test).to(device)    # Move train features test to selected device (GPU or CPU)\n",
        "\n",
        "# Convert y labels to float tensors\n",
        "y_train = torch.LongTensor(y_train).to(device)   # Move train label  data to selected device (GPU or CPU)\n",
        "y_test = torch.LongTensor(y_test).to(device)     # Move train label data to selected device (GPU or CPU)\n",
        "\n",
        "# Set criterion of model to measure the error, how far off the predictions are from the data\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose Adam Optimizer, lr = learning rate (if error doesn't go down after a bunch of iterations (epochs), lower our learning rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Check model\n",
        "model.parameters"
      ],
      "metadata": {
        "id": "5iTG1kM8Hbzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Readjust learning rate if retraining\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train model\n",
        "# Epoch? (one run thru all the training data in the neural network)\n",
        "epochs = 1000\n",
        "losses = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(epochs):\n",
        "  # Go forward and get a prediction\n",
        "  y_pred = model.forward(X_train) # Get predicted results\n",
        "\n",
        "  # Measure the loss/error\n",
        "  loss = criterion(y_pred, y_train) # Predicted value vs y_train value\n",
        "\n",
        "  # Loss tracking\n",
        "  losses.append(loss.detach().cpu().numpy()) # Added .cpu() for GPU loss tracking, remove if using CPU\n",
        "\n",
        "  # Print every 10 epoch\n",
        "  if i%10 == 0:\n",
        "    print(f'Epoch : {i} and loss : {loss}')\n",
        "\n",
        "  # Do back propagation: take error rate of forward propagation and feed it back thru the neural network to fine tune the weights\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"\\nElapsed Time: {elapsed_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "z6YI-JdiMmt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create graph\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.ylabel(\"Loss/Error\")\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "metadata": {
        "id": "luLJwN4jPkNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test data set\n",
        "with torch.no_grad(): # Basically turn off back propagation\n",
        "  y_eval = model.forward(X_test) # X_test are features from test set, y_eval will be predictions\n",
        "  loss = criterion(y_eval, y_test) # Find the loss or error\n",
        "\n",
        "  print(loss)"
      ],
      "metadata": {
        "id": "1RNOK4P1Qgr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate 2\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(X_test):\n",
        "    y_val = model.forward(data)\n",
        "\n",
        "    # Will tell what result class neural network think it is\n",
        "    print(f'{i+1}) \\t {str(y_val)} \\t\\t {y_test[i]} \\t {y_val.argmax().item()}')\n",
        "\n",
        "    # Correct or not\n",
        "    if y_val.argmax().item() == y_test[i]:\n",
        "      correct +=1\n",
        "\n",
        "# Percentage correct\n",
        "correct_percent = (correct/len(y_test)) * 100\n",
        "\n",
        "print(f'\\n{correct}/{len(y_test)} correct predictions ({round(correct_percent, 2)}%)')"
      ],
      "metadata": {
        "id": "-imxjwRhSyOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save MODEL\n",
        "torch.save(model.state_dict(), 'mymodel.pt')"
      ],
      "metadata": {
        "id": "S4pi8pJdXtZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MODEL\n",
        "new_model = Model()\n",
        "new_model.load_state_dict(torch.load('mymodel.pt'))\n",
        "\n",
        "# Make sure model is loaded correctly\n",
        "new_model.eval()"
      ],
      "metadata": {
        "id": "AmzV37SnYN4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test new data\n",
        "new_data = torch.tensor([4, 3, 1, 0.2]) # Input test features\n",
        "\n",
        "with torch.no_grad():\n",
        "  print(f'{new_model(new_data)} {new_model(new_data).argmax().item()}')"
      ],
      "metadata": {
        "id": "we0Rzu8uV-_0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}